{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple iteration for systems of linear equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, generate a random diagonally dominant matrix, for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rndm = np.random.RandomState(1234)\n",
    "\n",
    "n = 10\n",
    "A = rndm.uniform(size=(n, n)) + np.diagflat([15]*n)\n",
    "b = rndm.uniform(size=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I.  Jacobi iteration\n",
    "\n",
    "Given\n",
    "\n",
    "$$\n",
    "A x = b\n",
    "$$\n",
    "\n",
    "separate the diagonal part $D$,\n",
    "\n",
    "$$ A = D + (A - D) $$\n",
    "\n",
    "and write\n",
    "\n",
    "$$\n",
    "x = D^{-1} (D - A) x + D^{-1} b\\;.\n",
    "$$\n",
    "\n",
    "Then iterate\n",
    "\n",
    "$$\n",
    "x_{n + 1} = B x_{n} + c\\;,\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "B = D^{-1} (D - A) \\qquad \\text{and} \\qquad c = D^{-1} b\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct the matrix and the r.h.s. for the Jacobi iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_1d = np.diag(A)\n",
    "\n",
    "B = -A.copy()\n",
    "np.fill_diagonal(B, 0)\n",
    "\n",
    "D = np.diag(diag_1d)\n",
    "invD = np.diag(1./diag_1d)\n",
    "BB = invD @ B \n",
    "c = invD @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "from numpy.testing import assert_allclose\n",
    "\n",
    "assert_allclose(-B + D, A)\n",
    "\n",
    "\n",
    "# xx is a \"ground truth\" solution, compute it using a direct method\n",
    "xx = np.linalg.solve(A, b)\n",
    "\n",
    "np.testing.assert_allclose(A@xx, b)\n",
    "np.testing.assert_allclose(D@xx, B@xx + b)\n",
    "np.testing.assert_allclose(xx, BB@xx + c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that $\\| B\\| \\leqslant 1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36436161983015336"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(BB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the Jacobi iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 50\n",
    "\n",
    "x0 = np.ones(n)\n",
    "x = x0\n",
    "for _ in range(n_iter):\n",
    "    x = BB @ x + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  2.22044605e-16,  0.00000000e+00, -1.11022302e-16,\n",
       "        0.00000000e+00,  0.00000000e+00, -2.08166817e-17,  0.00000000e+00,\n",
       "        0.00000000e+00,  2.22044605e-16])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the result:\n",
    "\n",
    "A @ x - b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task I.1\n",
    "\n",
    "Collect the proof-of-concept above into a single function implementing the Jacobi iteration. This function should receive the r.h.s. matrix $A$, the l.h.s. vector `b`, and the number of iterations to perform.\n",
    "\n",
    "\n",
    "The matrix $A$ in the illustration above is strongly diagonally dominant, by construction. \n",
    "What happens if the diagonal matrix elements of $A$ are made smaller? Check the convergence of the Jacobi iteration, and check the value of the norm of $B$.\n",
    "\n",
    "(20% of the total grade)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobi_iter(A, b, n):\n",
    "    diag = np.diag(A)\n",
    "    B = np.diag(1. / diag) @ (np.diag(diag) - A)\n",
    "    print('Норма матицы B равна {}\\n'.format(np.linalg.norm(B)))\n",
    "    c = np.diag(1. / diag) @ b\n",
    "    x = np.ones(b.shape)\n",
    "    for i in range(n):\n",
    "        x = B @ x + c\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = 8\n",
    "A1 = rndm.uniform(size=(n1, n1)) + np.diagflat([15]*n1)\n",
    "b1 = rndm.uniform(size=n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Норма матицы B равна 0.29417978724692306\n",
      "\n",
      "[ 0.00000000e+00 -1.11022302e-16  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -1.11022302e-16 -1.11022302e-16  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "x1 = jacobi_iter(A1, b1, 30)\n",
    "\n",
    "print(A1 @ x1 - b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, в случае, когда матрица $A_1$ диагонально доминирующая, алгоритм хорошо сходится к правильному решению. Теперь заменим диагональные элементы маттрицы на её минимальный элемент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Норма матицы B равна 492.00142565985897\n",
      "\n",
      "[1.90466166e+78 2.52675686e+78 2.12003664e+78 1.94302934e+78\n",
      " 1.83504824e+78 2.75968872e+78 2.89982295e+78 2.44239878e+78]\n"
     ]
    }
   ],
   "source": [
    "np.fill_diagonal(A1, A1.min())\n",
    "\n",
    "x1_1 = jacobi_iter(A1, b1, 30)\n",
    "print(A1 @ x1_1 - b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом случае $\\| B\\| \\gg 1$, и, как следствие, алгоритм не сходится к правильному ответу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Seidel's iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task II.1\n",
    "\n",
    "Implement the Seidel's iteration. \n",
    "\n",
    "Test it on a random matrix. Study the convergence of iterations, relate to the norm of the iteration matrix.\n",
    "\n",
    "(30% of the total grade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Ax=b$$\n",
    "$$A=L+D+U$$\n",
    "$$\\Rightarrow x^{(k+1)}=-(L+D)^{-1}\\cdot U\\cdot x^{(k)}+(L+D)^{-1}\\cdot b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала напишем функцию, которая будет считать $(L+D)^{-1}$, то есть функцию, которая находит обратную матрицу к нижнетреугольной матрице*\n",
    "\n",
    "*необходимо, чтобы на главной диагонале у первоначальной матрицы не было нулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse(A):\n",
    "    n = A.shape[0]\n",
    "    inv = np.diag(1 / np.diag(A))\n",
    "    e = inv @ A\n",
    "    for i in range(n - 1):\n",
    "        k = np.eye(n)\n",
    "        k[i+1:,i] = -e[i+1:,i]\n",
    "        e = k @ e\n",
    "        inv = k @ inv\n",
    "    return inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сам метод Зейделя:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seidel_iter(A, b, t):\n",
    "    n = b.shape[0]\n",
    "    x = np.ones_like(b)\n",
    "    U = np.zeros_like(A)\n",
    "    LD = np.zeros_like(A)\n",
    "    for i in range(n):\n",
    "        U[:i,i] = A[:i,i]\n",
    "        LD[i:,i] = A[i:,i]\n",
    "    LD_inv = inverse(LD)\n",
    "    print('Норма матицы (L+D)^-1 равна {}\\n'.format(np.linalg.norm(LD_inv)))\n",
    "    for i in range(t):\n",
    "        x = -LD_inv @ U @ x + LD_inv @ b\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала проверим работу алгоритма на диагонально доминирующей матрице"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2 = 10\n",
    "A2 = rndm.uniform(size=(n2, n2)) + np.diagflat([15]*n2)\n",
    "b2 = rndm.uniform(size=n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Норма матицы (L+D)^-1 равна 0.20477939937010078\n",
      "\n",
      "[-1.11022302e-16  0.00000000e+00  1.11022302e-16  0.00000000e+00\n",
      " -1.11022302e-16 -1.11022302e-16  0.00000000e+00 -5.55111512e-17\n",
      "  0.00000000e+00  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "x2 = seidel_iter(A2, b2, 20)\n",
    "\n",
    "print(A2 @ x2 - b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, в этом случае алгоритм хорошо сходится к правильному результату\n",
    "\n",
    "Теперь проверим алгоритм на произвольной матрице"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n3 = 10\n",
    "A3 = rndm.uniform(size=(n3, n3))\n",
    "b3 = rndm.uniform(size=n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Норма матицы (L+D)^-1 равна 846.2518782201703\n",
      "\n",
      "[ 1.04120715e+53  7.32382284e+51  5.53691734e+52  6.00573842e+52\n",
      "  8.21709195e+52  8.98023193e+52  3.27438629e+52  3.56989409e+52\n",
      "  2.88502955e+52 -1.16307450e+36]\n"
     ]
    }
   ],
   "source": [
    "x3 = seidel_iter(A3, b3, 20)\n",
    "\n",
    "print(A3 @ x3 - b3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и ожидалось, при $\\| (L+D)^{-1}\\| > 1$ метод Зейделя также не сходится к правильному ответу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Minimum residual scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task III.1\n",
    "\n",
    "Implement the $\\textit{minimum residual}$ scheme: an explicit non-stationary method, where at each step you select the iteration parameter $\\tau_n$ to minimize the residual $\\mathbf{r}_{n+1}$ given $\\mathbf{r}_n$. Test it on a random matrix, study the convergence to the solution, in terms of the norm of the residual and the deviation from the ground truth solution (which you can obtain using a direct method). Study how the iteration parameter $\\tau_n$ changes as iterations progress.\n",
    "\n",
    "(50% of the grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ... ENTER YOUR CODE HERE ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
